{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(\"Fishdata/Data/train\")\n",
    "\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='fresh':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})\n",
    "print(filenames)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "directed-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "timely-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'nonfresh',1:'fresh'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sublime-dealer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 validated image filenames belonging to 2 classes.\n",
      "Found 4 validated image filenames belonging to 2 classes.\n",
      "Found 12 non-validated image filenames belonging to 2 classes.\n",
      "           filename  category\n",
      "0   nonfresh.16.jpg  nonfresh\n",
      "1   nonfresh.20.jpg  nonfresh\n",
      "2      fresh.19.jpg     fresh\n",
      "3      fresh.17.jpg     fresh\n",
      "4      fresh.15.jpg     fresh\n",
      "5      fresh.13.jpg     fresh\n",
      "6   nonfresh.15.jpg  nonfresh\n",
      "7   nonfresh.13.jpg  nonfresh\n",
      "8   nonfresh.19.jpg  nonfresh\n",
      "9   nonfresh.17.jpg  nonfresh\n",
      "10  nonfresh.14.jpg  nonfresh\n",
      "11     fresh.14.jpg     fresh\n",
      "          filename  category\n",
      "0     fresh.16.jpg     fresh\n",
      "1     fresh.18.jpg     fresh\n",
      "2     fresh.20.jpg     fresh\n",
      "3  nonfresh.18.jpg  nonfresh\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"Fishdata/Data/train\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"Fishdata/Data/train\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"Fishdata/Data/test1\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=None,\n",
    "                                                 validate_filenames=False)\n",
    "print(train_df)\n",
    "print(validate_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mathematical-comedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.2360 - accuracy: 0.9306 - val_loss: 0.3663 - val_accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 16s 1s/step - loss: 5.8845e-04 - accuracy: 1.0000 - val_loss: 1.2694 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4133 - val_accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.4683 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2.8278e-04 - accuracy: 1.0000 - val_loss: 3.0981 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2.7120e-04 - accuracy: 1.0000 - val_loss: 3.5339 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 16s 1s/step - loss: 1.0041e-04 - accuracy: 1.0000 - val_loss: 3.7836 - val_accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.4172e-05 - accuracy: 1.0000 - val_loss: 3.9998 - val_accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 14s 1s/step - loss: 4.4130e-06 - accuracy: 1.0000 - val_loss: 4.1588 - val_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.2148e-05 - accuracy: 1.0000 - val_loss: 4.2782 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "# model.fit(batch_size=None,\n",
    "#          steps_per_epoch=1)\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate,\n",
    "    steps_per_epoch=total_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "comprehensive-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1_freshfish_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interim-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"Fishdata/Data/test1\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-greensboro",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-656:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tang\\anaconda3\\envs\\PythonAdv\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Tang\\anaconda3\\envs\\PythonAdv\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Tang\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 566, in _run\n",
      "    sequence = list(range(len(self.sequence)))\n",
      "  File \"C:\\Users\\Tang\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 68, in __len__\n",
      "    return (self.n + self.batch_size - 1) // self.batch_size  # round up\n",
      "TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict= model.predict_generator(test_generator, steps=np.ceil(nb_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "\n",
    "test_df['category'] = test_df['category'].replace({ 'fresh': 1, 'nonfresh': 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-spouse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
